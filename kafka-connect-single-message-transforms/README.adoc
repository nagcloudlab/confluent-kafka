= ðŸŽ… ðŸŽ„ Twelve Days of SMT ðŸŽ„ ðŸŽ… 

Kafka Connect's Single Message Transform functionality is really useful for building data pipelines that modify the data passing through. For more complex transformations (such as those requiring state, or joins, etc) check out Kafka Streams or ksqlDB. 

_Each of the tutorials below has the full code available for you to try using the provided Docker Compose, and a complete ðŸŽ¥ https://www.youtube.com/watch?v=3Gj_SoyuTYk&list=PL5T99fPsK7pq7LiaaL-S6b7wQqzxyjgya[recording] to go with it._

* link:day1.adoc[Day 1] - `InsertField` - add message timestamp as a field - a sink
* link:day2.adoc[Day 2] - `ValueToKey` and `ExtractField` - set the message key - a field from the value
* link:day3.adoc[Day 3] - `Flatten` - turn a nested structure into a flat one
* link:day4.adoc[Day 4] - `RegexRouter` - change the topic name based on a pattern match and replacement
* link:day5.adoc[Day 5] - `MaskField` - mask the value of fields with a fixed replacement string
* link:day6.adoc[Day 6] - `InsertField` - same SMT as link:day1.adoc[Day 1], this time showing adding to the payload the topic name, Kafka message partition and offset, as well as hardcoded values 
* link:day7.adoc[Day 7] - `TimestampRouter` - change the topic name based on the timestamp of the Kafka message
* link:day8.adoc[Day 8] - `TimestampConverter` - Convert timestamp fields between unix epoch, string, Timestamp, Date, and Time
* link:day9.adoc[Day 9] - `Cast` - Convert string, numeric, and boolean field types
* link:day10.adoc[Day 10] - `ReplaceField` - Drop or rename fields
* link:day11.adoc[Day 11] - `Filter` and `predicates` - Drop messages based on conditions
* link:day12.adoc[Day 12] - Community Transformations (`ChangeTopicCase`, `ExtractTimestamp`, `TimestampNowField`)

ðŸŽ¥ **Check out the recordings for all of these in https://www.youtube.com/watch?v=3Gj_SoyuTYk&list=PL5T99fPsK7pq7LiaaL-S6b7wQqzxyjgya[this YouTube playlist]**